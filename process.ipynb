{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割节点和边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "'''\n",
    "split link\n",
    "'''\n",
    "if not os.path.exists(\"splitEdge\"):\n",
    "    os.mkdir(\"splitEdge\")\n",
    "\n",
    "df = pd.read_csv('./data/Link.csv')\n",
    "\n",
    "for key, group in tqdm(df.groupby(\"relation\")):\n",
    "\n",
    "    # group = group.drop(columns='relation')\n",
    "    group.reset_index(drop=True, inplace=True)\n",
    "    group.rename(columns={\"relation\": \":TYPE\",\n",
    "                          \"source\": \":START_ID\",\n",
    "                          \"target\": \":END_ID\"},  inplace=True)\n",
    "\n",
    "    if key in [\"r_cert\", \"r_subdomain\", \"r_request_jump\", \"r_dns_a\"]:\n",
    "        group.insert(group.shape[1], \"weight:int\", 2)\n",
    "    elif key in [\"r_cert_chain\", \"r_cname\"]:\n",
    "        group.insert(group.shape[1], \"weight:int\", 1)\n",
    "    group.to_csv(\n",
    "        './splitEdge/' + key + '.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "split node\n",
    "'''\n",
    "# get work Path\n",
    "path = os.getcwd()\n",
    "# read csv file\n",
    "dataFrame = pd.read_csv(path+\"\\\\data\\\\Node.csv\")\n",
    "community = pd.read_csv('./data/node-community.csv')\n",
    "dataFrame = pd.merge(dataFrame, community, left_on='id',\n",
    "                right_on='id', how='left')\n",
    "del community\n",
    "# group\n",
    "groups = dataFrame.groupby(\"type\")\n",
    "\n",
    "Domain_gp = groups.get_group(\"Domain\")\n",
    "IP_gp = groups.get_group(\"IP\")\n",
    "Cert_gp = groups.get_group(\"Cert\")\n",
    "Register_Name_gp = groups.get_group(\"Whois_Name\")\n",
    "Register_Email_gp = groups.get_group(\"Whois_Email\")\n",
    "Register_Phone_gp = groups.get_group(\"Whois_Phone\")\n",
    "IPC_gp = groups.get_group(\"IP_C\")\n",
    "ASN_gp = groups.get_group(\"ASN\")\n",
    "\n",
    "# split DF\n",
    "Domain = Domain_gp.set_index(\"id\")\n",
    "IP = IP_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "Cert = Cert_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "Register_Name = Register_Name_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "Register_Email = Register_Email_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "Register_Phone = Register_Phone_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "IPC = IPC_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "ASN = ASN_gp.drop(\"industry\", axis=1).set_index(\"id\")\n",
    "\n",
    "if not os.path.exists(\"splitNode\"):\n",
    "    os.mkdir(\"splitNode\")\n",
    "Domain.to_csv(path+\"\\\\splitNode\\\\Domain.csv\", encoding='utf_8_sig')\n",
    "print(\"Domain finished\")\n",
    "IP.to_csv(path+\"\\\\splitNode\\\\IP.csv\", encoding='utf_8_sig')\n",
    "print(\"IP finished\")\n",
    "Cert.to_csv(path+\"\\\\splitNode\\\\Cert.csv\", encoding='utf_8_sig')\n",
    "print(\"Domain finished\")\n",
    "Register_Name.drop(columns=[\"community\"], inplace=True)\n",
    "Register_Name.to_csv(path+\"\\\\splitNode\\\\Register_Name.csv\",\n",
    "                     encoding='utf_8_sig')\n",
    "print(\"Register_Name finished\")\n",
    "Register_Email.drop(columns=[\"community\"], inplace=True)\n",
    "Register_Email.to_csv(\n",
    "    path+\"\\\\splitNode\\\\Register_Email.csv\", encoding='utf_8_sig')\n",
    "print(\"Register_Email finished\")\n",
    "Register_Phone.drop(columns=[\"community\"], inplace=True)\n",
    "Register_Phone.to_csv(\n",
    "    path+\"\\\\splitNode\\\\Register_Phone.csv\", encoding='utf_8_sig')\n",
    "print(\"Register_Phone finished\")\n",
    "IPC.drop(columns=[\"community\"], inplace=True)\n",
    "IPC.to_csv(path+\"\\\\splitNode\\\\IPC.csv\", encoding='utf_8_sig')\n",
    "print(\"IPC finished\")\n",
    "ASN.drop(columns=[\"community\"], inplace=True)\n",
    "ASN.to_csv(path+\"\\\\splitNode\\\\ASN.csv\", encoding='utf_8_sig')\n",
    "print(\"ASN finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并节点，重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import case\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"split industry\")\n",
    "\n",
    "dict_map = {\n",
    "    \"A\": \"porn\",\n",
    "    \"B\": \"gambling\",\n",
    "    \"C\": \"fraud\",\n",
    "    \"D\": \"drug\",\n",
    "    \"E\": \"gun\",\n",
    "    \"F\": \"hacker\",\n",
    "    \"G\": \"trading\",\n",
    "    \"H\": \"pay\",\n",
    "    \"I\": \"other\"\n",
    "}\n",
    "nodepath = './splitNode/'\n",
    "edgepath = './splitEdge/'\n",
    "saveNodePath = './processedData/Node/'\n",
    "saveEdgePath = './processedData/Edge/'\n",
    "if not os.path.exists(saveNodePath):\n",
    "    os.makedirs(saveNodePath)\n",
    "if not os.path.exists(saveEdgePath):\n",
    "    os.makedirs(saveEdgePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将email，phone，name作为属性添加到domain上，并将industry拆分成7种犯罪属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merge domain and (email, name, phone)\n",
    "Split industry into 9 attributes\n",
    "'''\n",
    "def apply_split(row):\n",
    "    res = re.findall('[A-Z]', row['industry'])\n",
    "    for s in res:\n",
    "        row[dict_map[s]] = True\n",
    "    row[\"weight:int\"] = len(res)\n",
    "    return row\n",
    "\n",
    "df = pd.read_csv(nodepath + 'Domain.csv')\n",
    "\n",
    "# merge domain & email\n",
    "df_whois_Email = pd.read_csv(edgepath + 'r_whois_email.csv')\n",
    "df_whois_Email.drop_duplicates(\n",
    "    subset=[':START_ID'], keep='first', inplace=True)\n",
    "df_Email = pd.read_csv(nodepath + 'Register_Email.csv')\n",
    "\n",
    "df = pd.merge(df, df_whois_Email, left_on='id',\n",
    "              right_on=':START_ID', how='left')\n",
    "df = pd.merge(df, df_Email, left_on=':END_ID', right_on='id', how='left')\n",
    "\n",
    "df = df.drop(columns=[\":TYPE\", \":START_ID\", \":END_ID\", \"type_y\"])\n",
    "df.rename(columns={\"id_x\": \"id\",\n",
    "                   \"id_y\": \"email_id\",\n",
    "                   \"name_x\": \"name\",\n",
    "                   \"type_x\": \"type\",\n",
    "                   \"name_y\": \"email\",\n",
    "                   \"community\": \"community:int\"},  inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "# merge domain & name\n",
    "df_whois_Name = pd.read_csv(edgepath + 'r_whois_name.csv')\n",
    "df_whois_Name.drop_duplicates(subset=[':START_ID'], keep='first', inplace=True)\n",
    "df_Name = pd.read_csv(nodepath + 'Register_Name.csv')\n",
    "\n",
    "df = pd.merge(df, df_whois_Name, left_on='id',\n",
    "              right_on=':START_ID', how='left')\n",
    "df = pd.merge(df, df_Name, left_on=':END_ID', right_on='id', how='left')\n",
    "\n",
    "df = df.drop(columns=[\":TYPE\", \":START_ID\", \":END_ID\", \"type_y\"])\n",
    "df.rename(columns={\"id_x\": \"id\",\n",
    "                   \"id_y\": \"register_id\",\n",
    "                   \"name_x\": \"name\",\n",
    "                   \"type_x\": \"type\",\n",
    "                   \"name_y\": \"register\"},  inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "# merge domain & phone\n",
    "df_whois_Phone = pd.read_csv(edgepath + 'r_whois_Phone.csv')\n",
    "df_whois_Phone.drop_duplicates(\n",
    "    subset=[':START_ID'], keep='first', inplace=True)\n",
    "df_Phone = pd.read_csv(nodepath + 'Register_Phone.csv')\n",
    "\n",
    "df = pd.merge(df, df_whois_Phone, left_on='id',\n",
    "              right_on=':START_ID', how='left')\n",
    "df = pd.merge(df, df_Phone, left_on=':END_ID', right_on='id', how='left')\n",
    "\n",
    "df = df.drop(columns=[\":TYPE\", \":START_ID\", \":END_ID\", \"type_y\"])\n",
    "df.rename(columns={\"id_x\": \"id:ID\",\n",
    "                   \"id_y\": \"phone_id\",\n",
    "                   \"name_x\": \"name\",\n",
    "                   \"type_x\": \":LABEL\",\n",
    "                   \"name_y\": \"phone\"},  inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "\n",
    "for insert_c in list(dict_map.values()):\n",
    "    df.insert(df.shape[1], insert_c, False)\n",
    "\n",
    "df.insert(df.shape[1], \"weight:int\", 0)\n",
    "\n",
    "# df.apply的tqdm写法，用来显示进度条\n",
    "df = df.progress_apply(apply_split, axis=1)\n",
    "df = df.drop(columns=\"industry\")\n",
    "df[\"community:int\"] = df[\"community:int\"].astype(int)\n",
    "df.to_csv(saveNodePath + 'Domain.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将asn，ipc作为属性添加到IP上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merge IP and (asn, cidr)\n",
    "'''\n",
    "df = pd.read_csv(nodepath + 'IP.csv')\n",
    "\n",
    "# merge IP & ASN\n",
    "df_r_asn = pd.read_csv(edgepath + 'r_asn.csv')\n",
    "df_r_asn.drop_duplicates(subset=[':START_ID'], keep='first', inplace=True)\n",
    "df_ASN = pd.read_csv(nodepath + 'ASN.csv')\n",
    "\n",
    "df = pd.merge(df, df_r_asn, left_on='id', right_on=':START_ID', how='left')\n",
    "df = pd.merge(df, df_ASN, left_on=':END_ID', right_on='id', how='left')\n",
    "\n",
    "\n",
    "df = df.drop(columns=[\":TYPE\", \":START_ID\", \":END_ID\", \"type_y\"])\n",
    "df.rename(columns={\"id_x\": \"id\",\n",
    "                   \"id_y\": \"asn_id\",\n",
    "                   \"name_x\": \"name\",\n",
    "                   \"type_x\": \"type\",\n",
    "                   \"name_y\": \"asn\",\n",
    "                   \"community\": \"community:int\"},  inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "# merge IP & IPC\n",
    "df_cidr = pd.read_csv(edgepath + 'r_cidr.csv')\n",
    "df_cidr.drop_duplicates(subset=[':START_ID'], keep='first', inplace=True)\n",
    "df_IPC = pd.read_csv(nodepath + 'IPC.csv')\n",
    "\n",
    "df = pd.merge(df, df_cidr, left_on='id', right_on=':START_ID', how='left')\n",
    "df = pd.merge(df, df_IPC, left_on=':END_ID', right_on='id', how='left')\n",
    "\n",
    "\n",
    "df = df.drop(columns=[\":TYPE\", \":START_ID\", \":END_ID\", \"type_y\"])\n",
    "df.rename(columns={\"id_x\": \"id:ID\",\n",
    "                   \"id_y\": \"ipc_id\",\n",
    "                   \"name_x\": \"name\",\n",
    "                   \"type_x\": \":LABEL\",\n",
    "                   \"name_y\": \"ipc\"},  inplace=True)\n",
    "print(df.columns)\n",
    "df[\"community:int\"] = df[\"community:int\"].astype(int)\n",
    "df.to_csv(saveNodePath + 'IP.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重命名cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rename Cert\n",
    "'''\n",
    "df_cert = pd.read_csv(nodepath + 'Cert.csv')\n",
    "df_cert.rename(columns={\"id\": \"id:ID\",\n",
    "                        \"type\": \":LABEL\",\n",
    "                        \"community\": \"community:int\"},  inplace=True)\n",
    "print(df_cert.columns)\n",
    "df_cert[\"community:int\"] = df_cert[\"community:int\"].astype(int)\n",
    "df_cert.to_csv(saveNodePath + 'Cert.csv',\n",
    "               index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重命名link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Select Edge\n",
    "'''\n",
    "splitEdge = os.listdir(edgepath)\n",
    "for file in tqdm(splitEdge):\n",
    "    if file == 'r_cert_chain.csv':\n",
    "        copyfile(edgepath + file, saveEdgePath + 'cert-cert.csv')\n",
    "    elif file == 'r_cert.csv':\n",
    "        copyfile(edgepath + file, saveEdgePath + 'domain-cert.csv')\n",
    "    elif file == 'r_cname.csv':\n",
    "        copyfile(edgepath + file, saveEdgePath + 'domain-cname.csv')\n",
    "    elif file == 'r_dns_a.csv':\n",
    "        copyfile(edgepath + file, saveEdgePath + 'domain-IP.csv')\n",
    "    elif file == 'r_request_jump.csv':\n",
    "        copyfile(edgepath + file, saveEdgePath + 'domain-domain.csv')\n",
    "    elif file == 'r_subdomain.csv':\n",
    "        copyfile(edgepath + file, saveEdgePath + 'domain-subdomain.csv')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# （没用）合并社区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "node = pd.read_csv('./data/Node.csv')\n",
    "community = pd.read_csv('./data/node-community.csv')\n",
    "node = pd.merge(node, community, left_on='id',\n",
    "                right_on='id', how='left')\n",
    "# node.drop(columns=[\"name\", \"type\", \"industry\"], inplace=True)\n",
    "del community\n",
    "\n",
    "with open('modify.csv','a+', encoding='utf-8-sig',newline='') as f:#r为标识符，表示只读\n",
    "    writer = csv.writer(f)\n",
    "    # cname = pd.read_csv(\n",
    "    #     './processedData/Edge/domain-cname.csv').drop(columns=[\":TYPE\", \"weight:int\"])\n",
    "    # for i, row in tqdm(cname.iterrows()):\n",
    "    #     c_start = node[node[\"id\"] == row[\":START_ID\"]][\"community\"].values[0]\n",
    "    #     c_end = node[node[\"id\"] == row[\":END_ID\"]][\"community\"].values[0]\n",
    "    #     if(c_start != c_end):\n",
    "    #         writer.writerow([c_end, c_start])\n",
    "    #         node.loc[node[\"community\"] == c_end, [\"community\"]] = c_start\n",
    "        \n",
    "\n",
    "    subdomain = pd.read_csv(\n",
    "        './processedData/Edge/domain-subdomain.csv').drop(columns=[\":TYPE\", \"weight:int\"])\n",
    "    for i, row in tqdm(subdomain.iterrows()):\n",
    "        s_start = node[node[\"id\"] == row[\":START_ID\"]][\"community\"].values[0]\n",
    "        s_end = node[node[\"id\"] == row[\":END_ID\"]][\"community\"].values[0]\n",
    "        if(s_start != s_end):\n",
    "            writer.writerow([s_end, s_start])\n",
    "            node.loc[node[\"community\"] == s_end, [\"community\"]] = s_start\n",
    "        \n",
    "    node.to_csv('CommunityNode.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 社区连接图数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.concat([pd.read_csv('./processedData/Edge/cert-cert.csv', encoding=\"utf-8\"),\n",
    "                pd.read_csv('./processedData/Edge/domain-cert.csv', encoding=\"utf-8\"),\n",
    "                pd.read_csv('./processedData/Edge/domain-cname.csv', encoding=\"utf-8\"),\n",
    "                pd.read_csv('./processedData/Edge/domain-domain.csv', encoding=\"utf-8\"),\n",
    "                pd.read_csv('./processedData/Edge/domain-IP.csv', encoding=\"utf-8\"),\n",
    "                pd.read_csv('./processedData/Edge/domain-subdomain.csv', encoding=\"utf-8\")])\n",
    "df.columns = ['type', 'start', 'end', 'weight']\n",
    "df = pd.DataFrame(df, columns=['start', 'end'])\n",
    "df_Start = pd.DataFrame(df, columns=['start'])\n",
    "df_End = pd.DataFrame(df, columns=['end'])\n",
    "\n",
    "df_community_start = pd.read_csv(\n",
    "    './data/node-community.csv', encoding=\"utf-8\")\n",
    "df_community_end = pd.read_csv('./data/node-community.csv', encoding=\"utf-8\")\n",
    "df_community_start.columns = ['start', 'community']\n",
    "df_community_end.columns = ['end', 'community']\n",
    "\n",
    "start = pd.merge(df_Start, df_community_start, how='left')\n",
    "end = pd.merge(df_End, df_community_end, how='left')\n",
    "start.columns = ['start', 'communityS']\n",
    "end.columns = ['end', 'communityE']\n",
    "result = pd.concat([start, end], axis=1)\n",
    "print(result)\n",
    "SR = []\n",
    "ER = []\n",
    "for index, row in result.iterrows():\n",
    "    if(row['communityS'] != row['communityE']):\n",
    "        SR.append(row['communityS'])\n",
    "        ER.append(row['communityE'])\n",
    "\n",
    "Final = pd.DataFrame({'source': SR,\n",
    "                      'target': ER})\n",
    "dfFinal = Final.drop_duplicates()\n",
    "dfFinal.to_csv('community2community.csv', index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去掉社区节点数小于等于3的社区连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "c2c = pd.read_csv('./data/community2community.csv')\n",
    "c3 = pd.read_csv('./data/community-nodes-3.csv')\n",
    "c2c = c2c[(c2c.source.isin(c3.communityId.values))&(c2c.target.isin(c3.communityId.values))].reset_index(drop=True)\n",
    "\n",
    "c2c.to_csv('community2community-3.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv转json\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/community2community-3.csv')\n",
    "df.to_json('./app/public/community_link.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neighbour: 100%|██████████| 37614/37614 [04:04<00:00, 153.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# 社区节点加邻居\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"neighbour\")\n",
    "def fn(row):\n",
    "  res = set()\n",
    "  data = {'id':[row[\"id\"]]}\n",
    "  _ = pd.DataFrame(data)\n",
    "  _ = pd.merge(_, _df, how='left', left_on=\"id\", right_on=\"source\").drop(columns=[\"source\"])\n",
    "  _ = pd.merge(_, _df, how='left', left_on=\"id\", right_on=\"target\").drop(columns=[\"target_y\"]).dropna(axis=1,how='all')\n",
    "  if 'source' in _.columns:\n",
    "    res.update(_[\"source\"].values)\n",
    "  if 'target_x' in _.columns:\n",
    "    res.update(_[\"target_x\"].values)\n",
    "  row[\"neighbour\"] = list(res)\n",
    "  return row\n",
    "df = pd.read_json('./data/community_node.json')\n",
    "_df = pd.read_json('./data/community_link.json')\n",
    "df = df.progress_apply(fn, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('./data/community_node1.json', orient=\"records\")\n",
    "# df[df['neighbour'].str.len()!=0].to_json('./data/community_node2.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'key', 'node_num', 'wrong_num', 'porn', 'gambling', 'fraud',\n",
      "       'drug', 'gun', 'hacker', 'trading', 'pay', 'other', 'neighbour',\n",
      "       'wrong_list'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 适配lineup porn,gambling,fraud,drug,gun,hacker,hacker,pay,other\n",
    "df = df[df['neighbour'].str.len()!=0].drop(columns=[\"Domain\", \"Cert\"])\n",
    "df.to_json('./data/community_node2.json', orient=\"records\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'key', 'node_num', 'wrong_num', 'neighbour', 'wrong_list'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df[\"wrong_list\"] = df[[\"porn\",\"gambling\",\"fraud\",\"drug\",\"gun\",\"hacker\",\"trading\",\"pay\",\"other\"]].values.tolist()\n",
    "test = df.drop(columns=[\"porn\",\"gambling\",\"fraud\",\"drug\",\"gun\",\"hacker\",\"trading\",\"pay\",\"other\"], inplace=False)\n",
    "test.to_json('./data/community_node3.json', orient=\"records\")\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/25489 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6596\\3913202907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targetNode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddNode2Link\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/community_link1.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"records\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[1;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m         )\n\u001b[1;32m-> 7768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m                     \u001b[1;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m                 \u001b[1;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6596\\3913202907.py\u001b[0m in \u001b[0;36maddNode2Link\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/community_node.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maddNode2Link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sourceNode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m   \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targetNode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\Anaconda3\\envs\\ts\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"\")\n",
    "link = pd.read_json('./data/community_link.json')\n",
    "node = pd.read_json('./data/community_node.json')\n",
    "def addNode2Link(row):\n",
    "  row['sourceNode'] = node[node['id']==row['source']]\n",
    "  row['targetNode'] = node[node['id']==row['target']]\n",
    "  return row\n",
    "link = link.progress_apply(addNode2Link, axis=1)\n",
    "link.to_json('./data/community_link1.json', orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b2d9b31d3c403a70b2543a246ce306ec0df2865bb3d11e1e8547e68a4ec51ee"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('ts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
